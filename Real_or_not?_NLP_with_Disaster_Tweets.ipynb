{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real or not? NLP with Disaster Tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdV/62Wl30yxPBQms+npfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PearlSikka/language-ninja/blob/master/Real_or_not%3F_NLP_with_Disaster_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBxvuDYSbqWO"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGbDzQZAcK4W"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Upload the API token.\n",
        "def get_kaggle():\n",
        "  try:\n",
        "    import kaggle\n",
        "    return kaggle\n",
        "  except OSError:\n",
        "    pass\n",
        "\n",
        "  token_file = pathlib.Path(\"~/.kaggle/kaggle.json\").expanduser()\n",
        "  token_file.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  try:\n",
        "    from google.colab import files\n",
        "  except ImportError:\n",
        "    raise ValueError(\"Could not find kaggle token.\")\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  token_content = uploaded.get('kaggle.json', None)\n",
        "  if token_content:\n",
        "    token_file.write_bytes(token_content)\n",
        "    token_file.chmod(0o600)\n",
        "  else:\n",
        "    raise ValueError('Need a file named \"kaggle.json\"')\n",
        "  \n",
        "  import kaggle\n",
        "  return kaggle\n",
        "\n",
        "\n",
        "kaggle = get_kaggle()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA1sV1_ucYqM"
      },
      "source": [
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMjQYSXifzD3"
      },
      "source": [
        "df=pd.read_csv('/content/train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvJ9hIO4gKTf"
      },
      "source": [
        "train_df=df.loc[:,['id','text','target']]\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R2273PKgLCK"
      },
      "source": [
        "train_df.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_abZY5dgQVS"
      },
      "source": [
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "lem=WordNetLemmatizer()\n",
        "def cleaned_text(text):\n",
        "    split_word=text.split()\n",
        "    cleaned_word=\" \".join([lem.lemmatize(i) for i in split_word if i not in stopwords.words('english')\n",
        "    and not i.startswith('@')])\n",
        "    return cleaned_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo9b4FOSgS6B"
      },
      "source": [
        "train_df['text']=train_df['text'].apply(lambda x: cleaned_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLqXPIR7gXip"
      },
      "source": [
        "test_df=pd.read_csv('/content/test.csv')\n",
        "test_df['text']=test_df['text'].apply(lambda x: cleaned_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSMKMzJSgdES"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=2500)\n",
        "\n",
        "train_x=cv.fit_transform(train_df['text']).toarray()\n",
        "train_y=train_df['target'].values\n",
        "\n",
        "test_x=cv.transform(test_df['text']).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bAOVDOQgfuF"
      },
      "source": [
        "train_df['target'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QO2n2n8giEu"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model=MultinomialNB()\n",
        "model.fit(train_x,train_y)\n",
        "pred_y=model.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvx9BtSBgiu5"
      },
      "source": [
        "result=pd.DataFrame()\n",
        "result['id']=test_df['id']\n",
        "result['target']=pred_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUC1svaagnWR"
      },
      "source": [
        "result.to_csv('result.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYz58_TggrBN"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}